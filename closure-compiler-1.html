<!DOCTYPE html>
<html>
  <head>
    <title></title>
    <link rel="stylesheet" href="./styles.css">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  </head>

  <body>
    <div class="content">
      <section id="content" class="body">
        <a href="./index.html">&lt;</a>
        <time class="published">
        2015-04-20
        </time>
        <h1>
        What the heck is Google Closure Compiler?
        </h1>
        <div class="entry-content">
        <p>It &quot;compiles from JavaScript to better JavaScript&quot;, so why would any one want that?</p>
<p>According to the <a href='https://github.com/google/closure-compiler'>GitHub repo</a>, closure compiler does many amazing things:</p>
<ul><li>parses your JavaScript,</li><li>analyzes it,</li><li>removes dead code and rewrites</li><li>minimizes what&#39;s left</li><li>checks syntax, variable references, and types,</li><li>and warns about common JavaScript pitfalls</li></ul>

<p>That&#39;s pretty complicated. But no fear, this series will explore the Closure Compiler, one feature at a time.</p>
<p>Let&#39;s follow their instructions and try to run it from the command line.</p>
<pre><code>$ java -jar build/compiler.jar
var x = 17 + 25;</code></pre>

<p>The output we get is:</p>
<pre><code>var x=42;</code></pre>

<p>What noticeable differences are there?</p>
<ol><li><code>17 + 25</code> became <code>42</code></li><li>Space between and after <code>=</code> is gone</li></ol>

<p>So even for this simple one liner, closure compiler has managed to run 2 optimizations.</p>
<p>Let&#39;s examine these optimizations closer, and what better way to do that then jump into the debugger :)</p>
<h1 id="Runningfromthecommandline">Running from the command line</h1>

<p>We create file called <code>in1.js</code> with the contents <code>var x = 17 + 25</code>, and in our debug configuration
specify the program arguments as <code>--js_output_file=out.js in1.js</code>.</p>
<p>We do this because we don&#39;t want to be typing input in the Eclipse console (I don&#39;t know how to do that :P)</p>
<p>The initial part isn&#39;t that interesting, we just initiate the <code>CommandLineRunner</code></p>
<pre class='java'><code class='java'>    CommandLineRunner runner = new CommandLineRunner(args);
    if (runner.shouldRunCompiler()) {
      runner.run();
    }</code></pre><p><code>@CommandLineRunner.java#L1434-1437</code></p>
<p>Which delegates work to <code>AbstractCommandLineRunner</code>&#39;s <code>run()</code> method</p>
<pre class='java'><code class='java'>  public final void run() {
    int result = 0;
    int runs = 1;
    try {
      for (int i = 0; i &lt; runs &amp;&amp; result == 0; i++) {
        result = doRun();
      }</code></pre><p><code>@AbstractCommandLineRunner.java#L397-403</code></p>
<p>Which then hands off to <code>doRun()</code></p>
<h4 id="Warning">Warning</h4>

<blockquote><p>I had to go into my debug configuration in eclipse and add the folder where <code>externs.zip</code> was located in so <code>getResourceAsStream</code> could find the file.
Basically <code>createExterns</code> copies all the files in <code>externs.zip</code> into a list that will be used later.</p>
</blockquote>

<p>The next steps sets up the compiler with the appropriate options</p>
<pre class='java'><code class='java'>  protected int doRun() throws FlagUsageException, IOException {
    Compiler.setLoggingLevel(Level.parse(config.loggingLevel));

    List&lt;SourceFile&gt; externs = createExterns();

    compiler = createCompiler();
    B options = createOptions();</code></pre><p><code>@AbstractCommandLineRunner.java#L807-813</code></p>
<p>The part where usually the runner will wait for user input is here:</p>
<pre class='java'><code class='java'>      List&lt;SourceFile&gt; inputs = createSourceInputs(jsFiles);
      if (config.skipNormalOutputs) {
        compiler.init(externs, inputs, options);
        compiler.hoistExterns();
      } else {
        result = compiler.compile(externs, inputs, options);
      }</code></pre><p><code>@AbstractCommandLineRunner.java#L847-853</code></p>
<p>But because we supplied arguments to the parameter, it reads from that file and not <code>stdin</code>.</p>
<p>There are some set up steps again, and finally we jump into the <code>compile</code> method, the meat of
which happens in a separate thread it seems:</p>
<pre class='java'><code class='java'>  private Result compile() {
    return runInCompilerThread(new Callable&lt;Result&gt;() {
      @Override
      public Result call() throws Exception {
        compileInternal();
        return getResult();
      }
    });
  }</code></pre><p><code>@Compiler.java#L652-660</code></p>
<p>Because it is a separate thread, I had to set a breakpoint inside <code>compileInternal</code>
in order to take a look at what&#39;s happening.</p>
<h2 id="Insidethecompiler">Inside the compiler</h2>

<p>Some very small set up to process compiler options and initialize progress state, but
there&#39;s a very interesting comment here:</p>
<pre class='java'><code class='java'>  private void compileInternal() {
    setProgress(0.0, null);
    CompilerOptionsPreprocessor.preprocess(options);
    parse();
    // 15 percent of the work is assumed to be for parsing (based on some
    // minimal analysis on big JS projects, of course this depends on options)
    setProgress(0.15, &quot;parse&quot;);</code></pre><p><code>@Compiler.java#L741-747</code></p>
<p>We&#39;re not going to dive into the <code>parse</code> method, that&#39;s not what we&#39;re after.</p>
<p>From a cursory look into the method, <code>parse</code> parses the inputs and returns an AST. This AST is stored in the <code>jsRoot</code> instance variable</p>
<p>And we end up in the <code>optimize</code> method! Okay I have a feeling this is where things are going to get exciting.</p>
<pre class='java'><code class='java'>        optimize();</code></pre><p><code>@Compiler.java#L764</code></p>
<p>First it gathers up a list of optimizations that will be performed, e.g.</p>
<ul><li>gatherExternProperties,</li><li>garbageCollectChecks</li></ul>

<p>A list of all these optimizations can be found in the <code>getOptimizations</code> method of <code>DefaultPassConfig</code>.</p>
<p>From how the code looks like, each optimization is also called a <code>pass</code>.</p>
<pre class='java'><code class='java'>  public void optimize() {
    List&lt;PassFactory&gt; optimizations = getPassConfig().getOptimizations();
    if (optimizations.isEmpty()) {
      return;
    }</code></pre><p><code>@Compiler.java#L1951-1955</code></p>
<p>Observe how <code>optimizations</code> is a <code>List</code> of <code>PassFactory</code> (factory pattern).</p>
<p>The first pass is the <code>normalize</code> pass. It seems like for each pass there is a set of steps that must be followed, something like:</p>
<ol><li><code>startPass</code> is called with the name of the pass</li><li>actually process the pass</li><li><code>endPass</code> is called, probably for cleanup effects</li></ol>

<p><code>startPass</code> itself has a number of steps as well:</p>
<ol><li>check the current state of passing</li><li>set <code>currentPassName</code> to signify what pass it is</li><li>set <code>currentTracer</code> to a new <code>Tracer</code></li></ol>

<p>I haven&#39;t dug into what a <code>Tracer</code> does, but from the comments it looks like it figures out how long a particular action took, and thus will be useful when you want to pin point slow areas in the code.</p>
<p>So let&#39;s jump into the work that <code>normalize</code> actually does.</p>
<p>It&#39;s not difficult to see what it does, because most of it is well document in the <code>Normalize</code> class.</p>
<p>Here&#39;s directly quoting the docs:</p>
<pre class='java'><code class='java'>/**
 * The goal with this pass is to simplify the other passes,
 * by making less complex statements.
 *
 * Starting with statements like:
 *   var a = 0, b = foo();
 *
 * Which become:
 *   var a = 0;
 *   var b = foo();
 *
 * The key here is only to break down things that help the other passes
 * and can be put back together in a form that is at least as small when
 * all is said and done.</code></pre><p><code>@Normalize.java#L33-46</code></p>
<p>If you keep looking down, you see descriptions about the 7 things that this class does.</p>
<p>After some set up, the <code>process</code> method of <code>Normalize</code> is called, and that&#39;s where magic happens!</p>
<h2 id="TraversingVisiting">Traversing/Visiting</h2>

<p>The first step is strange to me at first sight:</p>
<pre class='java'><code class='java'>    new NodeTraversal(
        compiler, new NormalizeStatements(compiler, assertOnChange))
        .traverseRoots(externs, root);</code></pre><p><code>@Normalize.java#L116-118</code></p>
<p>It looks like this isn&#39;t doing anything. But we we look into what <code>NodeTraversal</code> does, it actually takes in a <code>Callback</code>, and when it traverses the AST (<code>traverseRoots</code>), it calls particular methods of <code>Callback</code> at different points of traversing.</p>
<p>For example, <code>traverseRoots</code> calls <code>traverseBranch</code></p>
<pre class='java'><code class='java'>      traverseBranch(externs, scopeRoot);</code></pre><p><code>@NodeTraversal.java#L306</code></p>
<p>and in <code>traverseBranch</code>, it calls the <code>visit</code> method of the callback</p>
<pre class='java'><code class='java'>    callback.visit(this, n, parent);</code></pre><p><code>@NodeTraversal.java#L577</code></p>
<p>In summary the <code>NodeTraversal</code> goes through the AST and at various points, asks the <code>Callback</code> if it wants to visit a particular node (Visitor pattern).</p>
<p>Now we can see what <code>NormalizeStatements</code> does.</p>
<p>There are really only 2 methods of interest here, <code>shouldTraverse</code> and <code>visit</code>.</p>
<p><code>shouldTraverse</code> is <code>NormalizeStatements</code>&#39;&#39; way of saying if it should descend down one level in the AST.</p>
<p><code>visit</code> is what <code>NormalizeStatements</code> will do to modify the AST.</p>
<p>Looking into <code>shouldTraverse</code>, we see that first, it always returns <code>true</code>, and it does some normalizations inside of this method</p>
<pre class='java'><code class='java'>    public boolean shouldTraverse(NodeTraversal t, Node n, Node parent) {
      doStatementNormalizations(n);

      return true;
    }</code></pre><p><code>@Normalize.java#L368-372</code></p>
<p>If we dive deeper into the code we can see very well written comments why certain normalizations are done in the <code>shouldTraverse</code> method, and why others are done in the <code>visit</code>.</p>
<p>For example, in <code>doStatementNormalizations</code>, the <code>extractForInitializer</code> method is called, and the comments are as such:</p>
<pre class='java'><code class='java'>    /**
     * Bring the initializers out of FOR loops.  These need to be placed
     * before any associated LABEL nodes. This needs to be done from the top
     * level label first so this is called as a pre-order callback (from
     * shouldTraverse).
     *
     * @param n The node to inspect.
     * @param before The node to insert the initializer before.
     * @param beforeParent The parent of the node before which the initializer
     *     will be inserted.
     */</code></pre><p><code>@Normalize.java#L561-571</code></p>
<p>Because it&#39;s a AST traversal implemented with callbacks, it wasn&#39;t easy to get to the code that was interesting. A lot of is was just descending the AST (in what looks like a depth first manner), before we finally get to the <code>visit</code> part of the code.</p>
<p>Particularly I hit a point where I ended up in this switch case:</p>
<pre class='java'><code class='java'>        case Token.SETTER_DEF:
          if (!compiler.getLifeCycleStage().isNormalizedObfuscated()) {
            annotateConstantsByConvention(n, parent);
          }
          break;</code></pre><p><code>@Normalize.java#L399-403</code></p>
<p>I couldn&#39;t understand what <code>Token.SETTER_DEF</code> meant, so I went to the Variables panel in eclipse and looked at what <code>n</code> was (the switch block switched on <code>n.getType()</code>), and saw that n was &quot;x&quot;.</p>
<p>The rest of the <code>process</code> method looks similar, where callbacks are passed into a travesal, with different callbacks doing different things.</p>
<p>The slight differences are the types of <code>Callback</code>s used.</p>
<p><code>NormalizeStatements</code> implements the <code>Callback</code> interface at the highest level, and there over 20 classes or abstract classes that implement this interface.</p>
<p><code>MakeDeclaredNamesUnique</code> implements the ScopedCallback, because when renaming variables, scope has to be considered. E.g. a variable that refers to a variable in the outer scope cannot be renamed to something different.</p>
<p>Here&#39;s something that caused me difficulty in reading this particular method: there are multiple layers of abstraction here, which makes it pretty confusing.</p>
<ol><li>It&#39;s not clear how many things <code>process</code> is actually doing.</li><li>The actions are inconsistent. In some places, the construction of a <code>NodeTraversal</code> using <code>new</code> and calling <code>traverseRoots</code> happens on the same line. But in others, the <code>Callback</code> is constructed separately from the <code>NodeTraversal</code>, which are separate from actually calling the <code>traverse</code> method. In other places, these 3 steps are separated into another method.</li></ol>

<p>Perhaps to clean up this method slightly, we can move each sub-processing step into its own method, like <code>removeDuplicateDeclarations</code></p>
<pre class='java'><code class='java'>    removeDuplicateDeclarations(externs, root);</code></pre><p><code>@Normalize.java#L138</code></p>
<p>Then <code>process</code> will look like this</p>
<pre class='java'><code class='java'>public void process(Node externs, Node root) {
    normalizeStatements(externs, root);
    makeDeclaredNamesUnique(externs, root);
    removeDuplicateDeclarations(externs, root);
    propagateConstantAnnotationsOverVars(externs, root);
    findExposeAnnotations(root)
}</code></pre>

<p>For our simple piece of code, <code>normalize</code> actually doesn&#39;t do anything, so that was a pretty long detour. But I think we will see the patterns in <code>normalize</code> again thorughout the codebase, so it is still useful to examine it.</p>
<p>For each <code>startPass</code>, there is its dual <code>endPass</code>, which stops the <code>Tracer</code> (so a tracer probably records how long each compiler pass took).</p>
<h1 id="ThePhaseOptimizer">The PhaseOptimizer</h1>

<p>And we&#39;re back in <code>optimize</code>! Here we hit something scary (to me) called the <code>PhaseOptimizer</code>.
We throw all the optimizations in to the <code>phaseOptimizer</code> via its <code>consume</code> method, and basically <code>consume</code> organizes these <code>PassFactory</code>-ies into <code>CompilePasses</code>.</p>
<p>Like its name suggest, <code>PhaseOptimizer</code> does some optimizations. These are (for now) too complicated to get into, but here are relevant portions of the code that describes what happens:</p>
<pre class='java'><code class='java'>  /**
   * Add the passes generated by the given factories to the compile sequence.
   * &lt;p&gt;
   * Automatically pulls multi-run passes into fixed point loops. If there
   * are 1 or more multi-run passes in a row, they will run together in
   * the same fixed point loop. The passes will run until they are finished
   * making changes.
   * &lt;p&gt;
   * The PhaseOptimizer is free to tweak the order and frequency of multi-run
   * passes in a fixed-point loop.
   */
  void consume(List&lt;PassFactory&gt; factories) {</code></pre><p><code>@PhaseOptimizer.java#L128-139</code></p>
<pre class='java'><code class='java'>  /**
   * A compound pass that contains atomic passes and runs them until they reach
   * a fixed point.
   * &lt;p&gt;
   * Notice that this is a non-static class, because it includes the closure
   * of PhaseOptimizer.
   */
  @VisibleForTesting
  class Loop implements CompilerPass {</code></pre><p><code>@PhaseOptimizer.java#L400-408</code></p>
<p>At the end of <code>consume</code>, what we have is <code>passes</code> which is a list of <code>CompilerPass</code>-es that will be run. We then call the <code>process</code> method of the <code>PhaseOptimizer</code>, which goes through each <code>CompilerPass</code> (in <code>passes</code>) and calls the <code>process</code> method of that <code>CompilerPass</code>.</p>
<p>This should look pretty familiar because <code>Normalize</code> actually implements <code>CompilerPass</code>, and so we have a clue of what happens in the <code>process</code> method of each <code>CompilerPass</code>.</p>
<p>I wanted to figure out which exact <code>CompilerPass</code> was causing the change, so I added some if else and print statements to notify me when the nodes were changed by a pass. This is how it roughly looked like</p>
<pre class='java'><code class='java'>      String old_root_str = root.toStringTree();
      pass.process(externs, root);
      String new_root_str = root.toStringTree();
      if (old_root_str.contentEquals(new_root_str)){
          System.out.println(&quot;Same: &quot; + pass);
      } else {
          System.out.println(&quot;Pass: &quot; + pass + &quot; old: &quot; + old_root_str + &quot; new: &quot; + new_root_str);
      }</code></pre>

<p>What I found strange is that the <code>process</code> method of <code>PhaseOptimizer</code> ran twice. I found out because I had set breakpoints in that method.</p>
<p>In the first run of <code>process</code>, there was only 1 pass that caused a change: <code>inferConsts</code>, but I couldn&#39;t tell what changed based on the <code>toString()</code> output, so this isn&#39;t the pass we are interested in.</p>
<p>In the second run of <code>process</code>, we get this:</p>
<pre><code>Same: pass: beforeMainOptimizations
Pass: com.google.javascript.jscomp.PhaseOptimizer$Loop@dd37992 old: BLOCK [synthetic: 1]
    SCRIPT 1 [synthetic: 1] [source_file: in1.js] [input_id: InputId: in1.js]
        VAR 1 [source_file: in1.js]
            NAME x 1 [source_file: in1.js] [is_constant_var: 1]
                ADD 1 [source_file: in1.js]
                    NUMBER 17.0 1 [source_file: in1.js]
                    NUMBER 25.0 1 [source_file: in1.js]
 new: BLOCK [synthetic: 1] [change_time: 15]
    SCRIPT 1 [synthetic: 1] [source_file: in1.js] [input_id: InputId: in1.js]
        VAR 1 [source_file: in1.js]
            NAME x 1 [source_file: in1.js] [is_constant_var: 1]
                NUMBER 42.0 1 [source_file: in1.js]
Same: pass: beforeModuleMotion</code></pre>

<p>Bingo! Or not?</p>
<h2 id="Multiplepasses">Multiple passes</h2>

<p>We managed to figure out the pass that caused the optimization, but the name of the pass didn&#39;t really help at all.</p>
<p>But at least we know this pass happens before <code>beforeModuleMotion</code> and after <code>beforeMainOptimizations</code>, and because the list of <code>CompilerPass</code> is traversed in order, we can go into <code>DefaultPassConfig</code> and take a look at what is in between these 2 passes.</p>
<pre class='java'><code class='java'>    passes.addAll(getMainOptimizationLoop());</code></pre><p><code>@DefaultPassConfig.java#L594</code></p>
<p>This basically adds about 10+ <code>PassFactory</code>-ies to the list via the methods <code>getMainOptimizationLoop</code> and <code>getCodeRemovingPasses</code>.</p>
<p>By setting more debug breakpoints, I was able to narrow down my options to those found in <code>getCodeRemovingPasses</code>. Now I guess I just have to read what each pass does, or set breakpoints in every pass and observe what happens!</p>
<p>I think the former isn&#39;t a good idea, because the <code>PhaseOptimizer</code> might run each pass multiple times, and I&#39;ll just be debugging for a long time.</p>
<p>Here, I basically looked at each of them, read the comments and figure out what was likely to be the <code>CompilerPass</code> that did some work. My guess is that <code>PeepholeOptimizationsPass</code> did it.</p>
<p>Digging into the creation of <code>PeepholeOptimizationsPass</code> we see multiple kinds of peephole optimizations</p>
<pre class='java'><code class='java'>  /** Various peephole optimizations. */
  private final PassFactory peepholeOptimizations =
      new PassFactory(&quot;peepholeOptimizations&quot;, false) {
    @Override
    protected CompilerPass create(AbstractCompiler compiler) {
      final boolean late = false;
      return new PeepholeOptimizationsPass(compiler,
            new PeepholeMinimizeConditions(late),
            new PeepholeSubstituteAlternateSyntax(late),
            new PeepholeReplaceKnownMethods(late),
            new PeepholeRemoveDeadCode(),
            new PeepholeFoldConstants(late),
            new PeepholeCollectPropertyAssignments());
    }
  };</code></pre><p><code>@DefaultPassConfig.java#L1299-1313</code></p>
<p>I decided to brute force and figure out which of these are responsible for the AST changes, so I basically just removed these <code>AbstractPeepholeOptimization</code> one by one until the AST didn&#39;t change, that way I can figure out which one is responsible.</p>
<p>Here I stumbled upon a funny little problem that took me a good deal of debugging to solve.</p>
<p>Since we figure that the pass happens in <code>getMainOptimizationLoop</code>, I tried commenting that part out, but found that the pass still happened! That was really strange. Here&#39;s the part I commented out:</p>
<pre class='java'><code class='java'>    passes.add(createEmptyPass(&quot;beforeModuleMotion&quot;));</code></pre><p><code>@DefaultPassConfig.java#L596</code></p>
<p>What I ended up doing was to slowly comment out parts of the <code>getOptimizations</code> method, which <code>getMainOptimizationLoop</code> lives in, and see when I can get the the pass to not be processed.</p>
<p>While going through the file to comment the code I took glances at the code as well and found out that in multiple places <code>PeepholeOptimizationsPass</code> was inserted in to the list of <code>CompilerPass</code>!</p>
<pre class='java'><code class='java'>        passes.add(peepholeOptimizations);</code></pre><p><code>@DefaultPassConfig.java#L711</code></p>
<pre class='java'><code class='java'>      passes.add(latePeepholeOptimizations);</code></pre><p><code>@DefaultPassConfig.java#L752</code></p>
<p>To reduce the surface area of search, we will comment out all of these except for 1,</p>
<pre class='java'><code class='java'>        passes.add(peepholeOptimizations);</code></pre><p><code>@DefaultPassConfig.java#L711</code></p>
<p>Now we can proceed to comment out parts of <code>peepholeOptimizations</code> to figure out which exact <code>AbstractPeepholeOptimization</code> is doing the work, which is <code>PeepholeFoldConstants</code>.</p>
<p>This optimzation is not that simple to understand because it is made up of multiple smaller peephole optimizations.</p>
<p>Let&#39;s start from the top, which is a <code>PeepholeOptimizationsPass</code>. As per normal, this is a <code>CompilerPass</code>, so the <code>process</code> method is where this happen.</p>
<pre class='java'><code class='java'>  public void process(Node externs, Node root) {
    compiler.addChangeHandler(handler);
    beginTraversal();
    NodeTraversal.traverseChangedFunctions(compiler, new FunctionCallback() {
        @Override
        public void visit(AbstractCompiler compiler, Node root) {
          if (root.isFunction()) {
            root = root.getLastChild();
          }
          do {
            handler.reset();
            NodeTraversal.traverse(compiler, root, new PeepCallback());
          } while (retraverseOnChange &amp;&amp; handler.hasCodeChanged());
        }
      });
    endTraversal();
    compiler.removeChangeHandler(handler);
  }</code></pre><p><code>@PeepholeOptimizationsPass.java#L55-72</code></p>
<p>In <code>process</code> we see something different, the usage of <code>NodeTraversal.traverseChangedFunctions</code>.</p>
<p>This works similarly to the <code>Callbacks</code> we discussed above, except that the traversal only happens when functions are changed. The callback for this traversal is actually called <code>PeepCallback</code>, which runs each <code>AbstractPeepholeOptimization</code> when visiting each node by calling their <code>optimizeSubtree</code> method.</p>
<pre class='java'><code class='java'>  private class PeepCallback extends AbstractShallowCallback {
    @Override
    public void visit(NodeTraversal t, Node n, Node parent) {
      Node currentNode = n, newNode;
      boolean codeChanged = false;
      do {
        codeChanged = false;
        for (AbstractPeepholeOptimization optim : peepholeOptimizations) {
          newNode = optim.optimizeSubtree(currentNode);
          if (newNode != currentNode) {
            codeChanged = true;
            currentNode = newNode;
          }
          if (currentNode == null) {
            return;
          }
        }
      } while(codeChanged);
    }
  }</code></pre><p><code>@PeepholeOptimizationsPass.java#L74-93</code></p>
<h2 id="Finallywefoundit">Finally, we found it!</h2>

<p>Now we know where to look to find out what <code>PeepholeFoldConstants</code> does.</p>
<pre class='java'><code class='java'>  Node optimizeSubtree(Node subtree) {
    switch(subtree.getType()) {
      case Token.NEW:
        return tryFoldCtorCall(subtree);

      case Token.TYPEOF:
        return tryFoldTypeof(subtree);

      case Token.NOT:
      case Token.POS:
      case Token.NEG:
      case Token.BITNOT:
        tryReduceOperandsForOp(subtree);
        return tryFoldUnaryOperator(subtree);

      case Token.VOID:
        return tryReduceVoid(subtree);

      default:
        tryReduceOperandsForOp(subtree);
        return tryFoldBinaryOperator(subtree);
    }
  }</code></pre><p><code>@PeepholeFoldConstants.java#L78-100</code></p>
<p>Reading the code we can guess which switch case we will land into, the <code>default</code> case.</p>
<p>Here we&#39;re just going to make a guess which method does the optimization, I&#39;m going to pick <code>tryFoldBinaryOperator</code> because it sounds like it.</p>
<p>Jumping in we see a switch statement switching on the type of the subtree, which in our case is an addition. So we dive into the <code>tryFoldAdd</code> method.</p>
<pre class='java'><code class='java'>      case Token.ADD:
        return tryFoldAdd(subtree, left, right);</code></pre><p><code>@PeepholeFoldConstants.java#L151-152</code></p>
<p>We encounter some useful comments here so we can jump straight into the <code>else</code> branch.</p>
<pre class='java'><code class='java'>    } else {
      // Try arithmetic add
      Node result = tryFoldArithmeticOp(node, left, right);
      if (result != node) {
        return result;
      }
      return tryFoldLeftChildOp(node, left, right);
    }</code></pre><p><code>@PeepholeFoldConstants.java#L849-856</code></p>
<p>To verify that this is indeed the optimization we care about, we can jump into the method and just result whatever was passed in.</p>
<p>Success!</p>
<p>By commenting out the lines in <code>tryFoldArithmeticOp</code> and just return <code>n</code>, we can verify that the optimization does not run!</p>
<p>We can dig deeper and look into <code>performArithmeticOp</code>, but all we need to know is that it performs the addition, returning a Node. If the addition worked, Node would just be a number, which is the result of the addition (in our case thats 42), and replace <code>n</code> (which was a <code>add</code> subtree), with just a single node!</p>
<h1 id="Recap">Recap</h1>

<p>After this long post, I think it&#39;s worth recapping what happens.</p>
<ol><li>The compiler is set up with options, things like where to get the JS (stdin or a file?)</li><li>JavaScript is parsed into a tree</li><li>Gather up the list of optimizations that will be run</li><li>normalize (which is actually a compiler pass)</li><li>Feed the list of optimziations into the <code>PhaseOptimizer</code></li><li><code>PhaseOptimizer</code> will run through all the optimizations</li><li>Each <code>CompilerPass</code> will process the AST via callbacks when traversing the tree</li><li>Compiled JavaScript is output (to stdout or file)</li></ol>

<p>There&#39;s way more that goes on, like how the <code>PhaseOptimizer</code> runs the list of optimizations, fixed-point optimizations that can be run multiple times safely, the many different kinds of <code>Callback</code>s.</p>
<p>But at a high level, this is how things are run.</p>
<p>Conclusion:</p>
<ol><li>Open source is awesome. Because Google released this source code, we can look into the code to figure out how things work!</li><li>Debuggers are super useful. Because Eclipse, and other IDEs, are such fantastic tools, we can insert breakpoints, jump around code, build and run projects with ease.</li><li>Patterns are useful! In this dive into the code, we have already observed a couple of design patterns, namely the Visitor pattern and the Factory pattern. This has allowed the compiler to stay very flexible. I can imagine adding a new optimization pass by declaring a couple of new classes without touching the core of the compiler</li></ol>
        </div>
      </section>
      <footer>
      Powered by <a href="https://github.com/ngzhian/ocs">ocs</a>, a static blog generator written in OCaml.
      </footer>
    </div>
  </body>
</html>
